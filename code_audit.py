#!/usr/bin/env python3.11
"""
–ü–æ–ª–Ω—ã–π –∞—É–¥–∏—Ç –∫–æ–¥–∞ –º–∞–π–Ω–µ—Ä–∞
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º –≤–∞–ª–∏–¥–∞—Ç–æ—Ä–æ–≤ –∏ –≤—ã—è–≤–ª—è–µ—Ç –æ—à–∏–±–∫–∏
"""

import json
import sys
import os
from pathlib import Path
from typing import Dict, List, Any, Tuple
import importlib.util

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
sys.path.append(str(Path(__file__).parent))

class CodeAuditor:
    def __init__(self):
        self.issues = []
        self.warnings = []
        self.success_count = 0
        self.total_checks = 0
        
        # –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –≤–∞–ª–∏–¥–∞—Ç–æ—Ä–æ–≤
        self.twitter_required_fields = ["username", "text", "url", "tweet_hashtags"]
        self.reddit_required_fields = ["id", "url", "username", "communityName", "body", "createdAt", "dataType"]
        
    def log_issue(self, component: str, issue: str, severity: str = "ERROR"):
        """–õ–æ–≥–∏—Ä—É–µ—Ç –ø—Ä–æ–±–ª–µ–º—É"""
        self.issues.append({
            "component": component,
            "issue": issue,
            "severity": severity
        })
        print(f"‚ùå [{severity}] {component}: {issue}")
        
    def log_warning(self, component: str, warning: str):
        """–õ–æ–≥–∏—Ä—É–µ—Ç –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ"""
        self.warnings.append({
            "component": component,
            "warning": warning
        })
        print(f"‚ö†Ô∏è  {component}: {warning}")
        
    def log_success(self, component: str, message: str):
        """–õ–æ–≥–∏—Ä—É–µ—Ç —É—Å–ø–µ—Ö"""
        self.success_count += 1
        print(f"‚úÖ {component}: {message}")
        
    def check_twitter_field_population(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è –ø–æ–ª–µ–π Twitter"""
        print("\nüîç –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–æ–ª–µ–π Twitter...")
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º twikit_scraper.py
            if Path("twikit_scraper.py").exists():
                with open("twikit_scraper.py", "r") as f:
                    content = f.read()
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≤—Å–µ—Ö –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π
                for field in self.twitter_required_fields:
                    if field not in content:
                        self.log_issue("Twitter Scraper", f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ–µ –ø–æ–ª–µ: {field}")
                        return False
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è content_json
                if "content_json" in content and "username" in content and "url" in content:
                    self.log_success("Twitter Scraper", "–í—Å–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç")
                else:
                    self.log_issue("Twitter Scraper", "–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ content_json")
                    return False
                    
            else:
                self.log_issue("Twitter Scraper", "–§–∞–π–ª twikit_scraper.py –Ω–µ –Ω–∞–π–¥–µ–Ω")
                return False
                
        except Exception as e:
            self.log_issue("Twitter Scraper", f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏: {e}")
            return False
            
        return True
        
    def check_reddit_field_population(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è –ø–æ–ª–µ–π Reddit"""
        print("\nüîç –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–æ–ª–µ–π Reddit...")
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º reddit_custom_scraper.py
            if Path("scraping/reddit/reddit_custom_scraper.py").exists():
                with open("scraping/reddit/reddit_custom_scraper.py", "r") as f:
                    content = f.read()
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –∞–ª–∏–∞—Å–æ–≤
                if "communityName" in content and "createdAt" in content and "dataType" in content:
                    self.log_success("Reddit Scraper", "–ü—Ä–∞–≤–∏–ª—å–Ω—ã–µ –∞–ª–∏–∞—Å—ã –ø–æ–ª–µ–π –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è")
                else:
                    self.log_issue("Reddit Scraper", "–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –∞–ª–∏–∞—Å—ã –ø–æ–ª–µ–π")
                    return False
                    
            else:
                self.log_issue("Reddit Scraper", "–§–∞–π–ª reddit_custom_scraper.py –Ω–µ –Ω–∞–π–¥–µ–Ω")
                return False
                
        except Exception as e:
            self.log_issue("Reddit Scraper", f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏: {e}")
            return False
            
        return True
        
    def check_config_validation(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤–∞–ª–∏–¥–∞—Ü–∏—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        print("\nüîç –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏...")
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–≥—Ä—É–∑–∫—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
            if Path("scraping_config_test.json").exists():
                with open("scraping_config_test.json", "r") as f:
                    config = json.load(f)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
                if "scraper_configs" in config:
                    self.log_success("Config Validation", "–ü—Ä–∞–≤–∏–ª—å–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–π —Å–∫—Ä–∞–ø–µ—Ä
                    for scraper in config["scraper_configs"]:
                        if "scraper_id" in scraper and "labels_to_scrape" in scraper:
                            self.log_success("Config Validation", f"–°–∫—Ä–∞–ø–µ—Ä {scraper['scraper_id']} –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π")
                        else:
                            self.log_issue("Config Validation", f"–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ —Å–∫—Ä–∞–ø–µ—Ä–∞: {scraper}")
                            return False
                else:
                    self.log_issue("Config Validation", "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç scraper_configs –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
                    return False
                    
            else:
                self.log_issue("Config Validation", "–§–∞–π–ª –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω")
                return False
                
        except Exception as e:
            self.log_issue("Config Validation", f"–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {e}")
            return False
            
        return True
        
    def check_pydantic_models(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç Pydantic –º–æ–¥–µ–ª–∏"""
        print("\nüîç –ü—Ä–æ–≤–µ—Ä—è–µ–º Pydantic –º–æ–¥–µ–ª–∏...")
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–æ–¥–µ–ª—å RedditContent
            from scraping.reddit.model import RedditContent, RedditDataType
            
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞
            test_data = {
                "id": "test123",
                "url": "https://reddit.com/r/test/comments/test123/test_post/",
                "username": "testuser",
                "communityName": "r/test",
                "body": "Test post body",
                "createdAt": "2025-08-24T12:00:00Z",
                "dataType": "post"
            }
            
            reddit_content = RedditContent(**test_data)
            self.log_success("Pydantic Models", "RedditContent –º–æ–¥–µ–ª—å —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–æ–¥–µ–ª—å XContent
            try:
                from scraping.x.model import XContent
                self.log_success("Pydantic Models", "XContent –º–æ–¥–µ–ª—å –¥–æ—Å—Ç—É–ø–Ω–∞")
            except ImportError:
                self.log_warning("Pydantic Models", "XContent –º–æ–¥–µ–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
                
        except Exception as e:
            self.log_issue("Pydantic Models", f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –º–æ–¥–µ–ª–µ–π: {e}")
            return False
            
        return True
        
    def check_data_upload_format(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ñ–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏"""
        print("\nüîç –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏...")
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º HuggingFace uploader
            if Path("upload_utils/huggingface_uploader.py").exists():
                with open("upload_utils/huggingface_uploader.py", "r") as f:
                    content = f.read()
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö
                # HuggingFace uploader –∏—Å–ø–æ–ª—å–∑—É–µ—Ç SQL –∑–∞–ø—Ä–æ—Å—ã –∫ DataEntity
                if "DataEntity" in content and ("FROM DataEntity" in content or "SELECT" in content):
                    self.log_success("Data Upload", "–ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ DataEntity —á–µ—Ä–µ–∑ SQL")
                else:
                    self.log_issue("Data Upload", "–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ DataEntity")
                    return False
                    
            else:
                self.log_issue("Data Upload", "HuggingFace uploader –Ω–µ –Ω–∞–π–¥–µ–Ω")
                return False
                
        except Exception as e:
            self.log_issue("Data Upload", f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏: {e}")
            return False
            
        return True
        
    def check_quality_filters(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã"""
        print("\nüîç –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã...")
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º twikit_scraper.py –Ω–∞ –Ω–∞–ª–∏—á–∏–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤
            if Path("twikit_scraper.py").exists():
                with open("twikit_scraper.py", "r") as f:
                    content = f.read()
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –±–∞–∑–æ–≤—ã—Ö —Ñ–∏–ª—å—Ç—Ä–æ–≤
                if "is_english_basic" in content or "is_basic_spam" in content:
                    self.log_success("Quality Filters", "–ë–∞–∑–æ–≤—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã –∫–∞—á–µ—Å—Ç–≤–∞ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç")
                else:
                    self.log_warning("Quality Filters", "–§–∏–ª—å—Ç—Ä—ã –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç")
                    
            else:
                self.log_issue("Quality Filters", "–§–∞–π–ª twikit_scraper.py –Ω–µ –Ω–∞–π–¥–µ–Ω")
                return False
                
        except Exception as e:
            self.log_issue("Quality Filters", f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏: {e}")
            return False
            
        return True
        
    def check_error_handling(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É –æ—à–∏–±–æ–∫"""
        print("\nüîç –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –æ—à–∏–±–æ–∫...")
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ —Ñ–∞–π–ª—ã –Ω–∞ –Ω–∞–ª–∏—á–∏–µ try-catch –±–ª–æ–∫–æ–≤
            files_to_check = [
                "twikit_scraper.py",
                "scraping/reddit/reddit_custom_scraper.py",
                "upload_utils/huggingface_uploader.py"
            ]
            
            for file_path in files_to_check:
                if Path(file_path).exists():
                    with open(file_path, "r") as f:
                        content = f.read()
                    
                    if "try:" in content and "except" in content:
                        self.log_success("Error Handling", f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ –≤ {file_path}")
                    else:
                        self.log_warning("Error Handling", f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ –≤ {file_path}")
                else:
                    self.log_warning("Error Handling", f"–§–∞–π–ª {file_path} –Ω–µ –Ω–∞–π–¥–µ–Ω")
                    
        except Exception as e:
            self.log_issue("Error Handling", f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏: {e}")
            return False
            
        return True
        
    def check_performance_optimization(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        print("\nüîç –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏...")
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ cadence
            if Path("scraping_config_test.json").exists():
                with open("scraping_config_test.json", "r") as f:
                    config = json.load(f)
                
                for scraper in config.get("scraper_configs", []):
                    cadence = scraper.get("cadence_seconds", 0)
                    if 300 <= cadence <= 3600:  # 5 –º–∏–Ω—É—Ç - 1 —á–∞—Å
                        self.log_success("Performance", f"–û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π cadence: {cadence}s")
                    else:
                        self.log_warning("Performance", f"–ù–µ–æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π cadence: {cadence}s")
                        
        except Exception as e:
            self.log_issue("Performance", f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏: {e}")
            return False
            
        return True
        
    def run_full_audit(self) -> Dict[str, Any]:
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—ã–π –∞—É–¥–∏—Ç"""
        print("üöÄ –ù–∞—á–∏–Ω–∞–µ–º –ø–æ–ª–Ω—ã–π –∞—É–¥–∏—Ç –∫–æ–¥–∞ –º–∞–π–Ω–µ—Ä–∞...\n")
        
        checks = [
            ("Twitter Field Population", self.check_twitter_field_population),
            ("Reddit Field Population", self.check_reddit_field_population),
            ("Config Validation", self.check_config_validation),
            ("Pydantic Models", self.check_pydantic_models),
            ("Data Upload Format", self.check_data_upload_format),
            ("Quality Filters", self.check_quality_filters),
            ("Error Handling", self.check_error_handling),
            ("Performance Optimization", self.check_performance_optimization)
        ]
        
        results = {}
        
        for check_name, check_func in checks:
            self.total_checks += 1
            try:
                result = check_func()
                results[check_name] = result
            except Exception as e:
                self.log_issue(check_name, f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
                results[check_name] = False
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
        report = {
            "summary": {
                "total_checks": self.total_checks,
                "successful_checks": self.success_count,
                "issues_found": len(self.issues),
                "warnings_found": len(self.warnings)
            },
            "issues": self.issues,
            "warnings": self.warnings,
            "results": results
        }
        
        return report
        
    def print_report(self, report: Dict[str, Any]):
        """–í—ã–≤–æ–¥–∏—Ç –æ—Ç—á–µ—Ç –æ–± –∞—É–¥–∏—Ç–µ"""
        print("\n" + "="*60)
        print("üìä –û–¢–ß–ï–¢ –û–ë –ê–£–î–ò–¢–ï –ö–û–î–ê")
        print("="*60)
        
        summary = report["summary"]
        print(f"üìà –í—Å–µ–≥–æ –ø—Ä–æ–≤–µ—Ä–æ–∫: {summary['total_checks']}")
        print(f"‚úÖ –£—Å–ø–µ—à–Ω—ã—Ö: {summary['successful_checks']}")
        print(f"‚ùå –ü—Ä–æ–±–ª–µ–º: {summary['issues_found']}")
        print(f"‚ö†Ô∏è  –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π: {summary['warnings_found']}")
        
        if report["issues"]:
            print("\nüö® –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –ü–†–û–ë–õ–ï–ú–´:")
            for issue in report["issues"]:
                print(f"  ‚Ä¢ {issue['component']}: {issue['issue']}")
                
        if report["warnings"]:
            print("\n‚ö†Ô∏è  –ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–Ø:")
            for warning in report["warnings"]:
                print(f"  ‚Ä¢ {warning['component']}: {warning['warning']}")
                
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        print("\nüéØ –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
        if summary['issues_found'] > 0:
            print("  1. –ò—Å–ø—Ä–∞–≤—å—Ç–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º")
            print("  2. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π")
            print("  3. –£–±–µ–¥–∏—Ç–µ—Å—å –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö")
        else:
            print("  1. –ö–æ–¥ –≥–æ—Ç–æ–≤ –∫ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—é")
            print("  2. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –ª–æ–∫–∞–ª—å–Ω—ã–µ —Ç–µ—Å—Ç—ã")
            print("  3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ä–∞–±–æ—Ç—É –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ")
            
        print("="*60)

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    auditor = CodeAuditor()
    report = auditor.run_full_audit()
    auditor.print_report(report)
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–æ–¥ –≤—ã—Ö–æ–¥–∞
    if report["summary"]["issues_found"] > 0:
        return 1
    else:
        return 0

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
